{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4756ec",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb0291",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion\n",
    "\n",
    "Load the raw weather CSV data and perform basic cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a795ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "raw_data_path = 'data/terai_districts_weather.csv'\n",
    "df_raw = pd.read_csv(raw_data_path, parse_dates=['Date'])\n",
    "\n",
    "# Normalize column names\n",
    "df_raw.columns = [c.strip() for c in df_raw.columns]\n",
    "\n",
    "# Basic info\n",
    "print(f\"Data shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumns: {df_raw.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {df_raw['Date'].min()} to {df_raw['Date'].max()}\")\n",
    "print(f\"\\nDistricts: {df_raw['District'].nunique()}\")\n",
    "print(df_raw['District'].unique())\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51735512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df_raw.isnull().sum())\n",
    "\n",
    "# Save processed version\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "df_raw.to_parquet('data/processed/weather.parquet', index=False)\n",
    "print(\"\\n✓ Saved to data/processed/weather.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5938e65",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create time-based, rolling, lag, and anomaly features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['doy'] = df['Date'].dt.dayofyear\n",
    "    df['doy_sin'] = np.sin(2*np.pi*df['doy']/365.25)\n",
    "    df['doy_cos'] = np.cos(2*np.pi*df['doy']/365.25)\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    return df\n",
    "\n",
    "def rolling_lags(df, group='District'):\n",
    "    df = df.sort_values([group,'Date']).copy()\n",
    "    g = df.groupby(group)\n",
    "    \n",
    "    # Rolling sums/means\n",
    "    df['precip_3d'] = g['Precip'].rolling(3, min_periods=1).sum().reset_index(0,drop=True)\n",
    "    df['precip_7d'] = g['Precip'].rolling(7, min_periods=1).sum().reset_index(0,drop=True)\n",
    "    df['maxT_3d_mean'] = g['MaxTemp_2m'].rolling(3, min_periods=1).mean().reset_index(0,drop=True)\n",
    "    df['temp_range_3d_max'] = g['TempRange_2m'].rolling(3, min_periods=1).max().reset_index(0,drop=True)\n",
    "    \n",
    "    # Lags for precip and temp\n",
    "    for lag in [1,2,3,7,14]:\n",
    "        df[f'precip_lag_{lag}'] = g['Precip'].shift(lag)\n",
    "        df[f'maxT_lag_{lag}'] = g['MaxTemp_2m'].shift(lag)\n",
    "    \n",
    "    # API-like index\n",
    "    alpha = 0.8\n",
    "    def compute_api(s):\n",
    "        api = []\n",
    "        prev = 0.0\n",
    "        for v in s.fillna(0):\n",
    "            prev = alpha*prev + v\n",
    "            api.append(prev)\n",
    "        return pd.Series(api, index=s.index)\n",
    "    df['API'] = g['Precip'].apply(lambda s: compute_api(s)).reset_index(0,drop=True)\n",
    "    return df\n",
    "\n",
    "def climatology_anomaly(df):\n",
    "    df = df.copy()\n",
    "    df['doy'] = df['Date'].dt.dayofyear\n",
    "    climatology = df.groupby(['District','doy'])[['MaxTemp_2m','Precip']].median().rename(\n",
    "        columns={'MaxTemp_2m':'clim_maxT','Precip':'clim_precip'}).reset_index()\n",
    "    df = df.merge(climatology, on=['District','doy'], how='left')\n",
    "    df['anom_maxT'] = df['MaxTemp_2m'] - df['clim_maxT']\n",
    "    df['anom_precip'] = df['Precip'] - df['clim_precip']\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df = pd.read_parquet('data/processed/weather.parquet')\n",
    "df = add_time_features(df)\n",
    "df = rolling_lags(df)\n",
    "df = climatology_anomaly(df)\n",
    "\n",
    "print(f\"Features created. New shape: {df.shape}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "new_cols = [c for c in df.columns if c not in df_raw.columns]\n",
    "print(new_cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682682aa",
   "metadata": {},
   "source": [
    "## 4. Labeling\n",
    "\n",
    "Create target labels for heatwave and flood events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d12ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_heatwave(df, pct=0.95, min_run=3, temp_col='MaxTemp_2m'):\n",
    "    df = df.sort_values(['District','Date']).copy()\n",
    "    # Compute district-specific percentile\n",
    "    p = df.groupby('District')[temp_col].transform(lambda s: s.quantile(pct))\n",
    "    df['heat_exceed'] = df[temp_col] > p\n",
    "    \n",
    "    # Compute run length of consecutive True values\n",
    "    def run_len(s):\n",
    "        runs = s.astype(int).groupby((s != s.shift()).cumsum()).cumsum() * s\n",
    "        return runs\n",
    "    df['heat_run'] = df.groupby('District')['heat_exceed'].transform(lambda s: run_len(s))\n",
    "    df['heatwave'] = df['heat_run'] >= min_run\n",
    "    return df\n",
    "\n",
    "def label_flood(df, p1_pct=0.99, p3_pct=0.98):\n",
    "    df = df.sort_values(['District','Date']).copy()\n",
    "    g = df.groupby('District')\n",
    "    df['precip_1d'] = df['Precip'].fillna(0)\n",
    "    df['precip_3d'] = g['precip_1d'].rolling(3, min_periods=1).sum().reset_index(0,drop=True)\n",
    "    df['precip_7d'] = g['precip_1d'].rolling(7, min_periods=1).sum().reset_index(0,drop=True)\n",
    "    \n",
    "    # Thresholds\n",
    "    p99 = g['precip_1d'].transform(lambda s: s.quantile(p1_pct))\n",
    "    p98_3d = g['precip_3d'].transform(lambda s: s.quantile(p3_pct))\n",
    "    df['precip_p99'] = p99\n",
    "    df['precip3_p98'] = p98_3d\n",
    "    \n",
    "    # Wetness flag\n",
    "    df['RH_2m_filled'] = df['RH_2m'].fillna(method='ffill').fillna(method='bfill')\n",
    "    df['wetness_flag'] = df['RH_2m_filled'] > g['RH_2m_filled'].transform(lambda s: s.quantile(0.9))\n",
    "    df['flood_proxy'] = ((df['precip_1d'] > df['precip_p99']) | (df['precip_3d'] > df['precip3_p98'])) & df['wetness_flag']\n",
    "    return df\n",
    "\n",
    "# Apply labeling\n",
    "df = label_heatwave(df)\n",
    "df = label_flood(df)\n",
    "\n",
    "# Save labeled data\n",
    "df.to_parquet('data/processed/weather_labeled.parquet', index=False)\n",
    "print(\"✓ Saved labeled data\")\n",
    "\n",
    "# Show label statistics\n",
    "print(f\"\\nHeatwave events: {df['heatwave'].sum()} ({df['heatwave'].mean()*100:.2f}%)\")\n",
    "print(f\"Flood events: {df['flood_proxy'].sum()} ({df['flood_proxy'].mean()*100:.2f}%)\")\n",
    "\n",
    "df[['Date', 'District', 'MaxTemp_2m', 'Precip', 'heatwave', 'flood_proxy']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72367bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatwave distribution by district\n",
    "heatwave_by_district = df.groupby('District')['heatwave'].mean() * 100\n",
    "heatwave_by_district.plot(kind='bar', ax=axes[0], color='orange')\n",
    "axes[0].set_title('Heatwave Frequency by District (%)')\n",
    "axes[0].set_ylabel('Percentage')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Flood distribution by district\n",
    "flood_by_district = df.groupby('District')['flood_proxy'].mean() * 100\n",
    "flood_by_district.plot(kind='bar', ax=axes[1], color='blue')\n",
    "axes[1].set_title('Flood Frequency by District (%)')\n",
    "axes[1].set_ylabel('Percentage')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ff844",
   "metadata": {},
   "source": [
    "## 5. LSTM Model Architecture\n",
    "\n",
    "Define the LSTM model for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58490f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM model for binary classification.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64, fc_size=32):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, fc_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, timesteps, features)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # Use last hidden state\n",
    "        out = self.fc1(h_n[-1])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out.squeeze(-1)  # Returns logits\n",
    "\n",
    "print(\"✓ LSTM model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e44644",
   "metadata": {},
   "source": [
    "## 6. Sequence Building\n",
    "\n",
    "Create sequences from time series data for LSTM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(df, timesteps=14, target='heatwave'):\n",
    "    \"\"\"\n",
    "    Build sequences for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with features and labels\n",
    "        timesteps: Number of timesteps in each sequence\n",
    "        target: Target column name ('heatwave' or 'flood_proxy')\n",
    "    \n",
    "    Returns:\n",
    "        X: Array of sequences (n_samples, timesteps, n_features)\n",
    "        y: Array of labels (n_samples,)\n",
    "        feature_cols: List of feature column names\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['District','Date']).copy()\n",
    "    \n",
    "    # Exclude non-feature columns\n",
    "    exclude_cols = ['Date', 'District', 'heatwave', 'flood_proxy', 'heat_exceed', 'heat_run',\n",
    "                    'precip_1d', 'precip_p99', 'precip3_p98', 'RH_2m_filled', 'wetness_flag']\n",
    "    feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for district, g in df.groupby('District'):\n",
    "        arr = g[feature_cols].values\n",
    "        lab = g[target].fillna(False).astype(int).values\n",
    "        \n",
    "        if len(arr) < timesteps + 1:\n",
    "            continue\n",
    "        \n",
    "        for i in range(timesteps, len(arr)):\n",
    "            seq = arr[i-timesteps:i]\n",
    "            sequences.append(seq)\n",
    "            targets.append(lab[i])\n",
    "    \n",
    "    X = np.array(sequences, dtype=np.float32)\n",
    "    y = np.array(targets, dtype=np.float32)\n",
    "    \n",
    "    # Replace NaN and inf values\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "print(\"✓ Sequence building function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77b6dd",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c83755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test data.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            # Apply sigmoid to get probabilities\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            all_preds.extend(probs.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    auc = roc_auc_score(all_targets, all_preds) if len(set(all_targets)) > 1 else 0.0\n",
    "    \n",
    "    return avg_loss, auc, all_preds, all_targets\n",
    "\n",
    "print(\"✓ Training and evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d99aa9",
   "metadata": {},
   "source": [
    "## 8. Train LSTM Model for Heatwave Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44184f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TARGET = 'heatwave'  # or 'flood_proxy'\n",
    "TIMESTEPS = 14\n",
    "HIDDEN_SIZE = 64\n",
    "FC_SIZE = 32\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"Training LSTM for {TARGET} prediction\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "# Load labeled data\n",
    "df_labeled = pd.read_parquet('data/processed/weather_labeled.parquet')\n",
    "\n",
    "# Build sequences\n",
    "X, y, feature_cols = build_sequences(df_labeled, timesteps=TIMESTEPS, target=TARGET)\n",
    "print(f\"\\nSequences shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Positive samples: {y.sum()} ({y.mean()*100:.2f}%)\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(f\"\\nTrain samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dc64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "nsamples, nt, nf = X_train.shape\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_flat = X_train.reshape(-1, nf)\n",
    "X_test_flat = X_test.reshape(-1, nf)\n",
    "\n",
    "scaler.fit(X_train_flat)\n",
    "X_train_scaled = scaler.transform(X_train_flat).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape)\n",
    "\n",
    "print(\"✓ Features scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device, model, loss, optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model = LSTMModel(input_size=nf, hidden_size=HIDDEN_SIZE, fc_size=FC_SIZE).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # More numerically stable\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"  Input size: {nf}\")\n",
    "print(f\"  Hidden size: {HIDDEN_SIZE}\")\n",
    "print(f\"  FC size: {FC_SIZE}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_auc': []\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_auc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val AUC: {val_auc:.4f}')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbc94a",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training History - Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC curve\n",
    "axes[1].plot(history['val_auc'], label='Val AUC', linewidth=2, color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('AUC')\n",
    "axes[1].set_title('Validation AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Val AUC: {max(history['val_auc']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb89f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final predictions\n",
    "_, _, test_probs, test_targets = evaluate(model, test_loader, criterion, device)\n",
    "test_preds = (np.array(test_probs) > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_targets, test_preds, target_names=['No Event', 'Event']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_targets, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Event', 'Event'],\n",
    "            yticklabels=['No Event', 'Event'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title(f'Confusion Matrix - {TARGET.upper()} Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94113b9f",
   "metadata": {},
   "source": [
    "## 10. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model_path = f'models/lstm_{TARGET}.pt'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_size': nf,\n",
    "    'hidden_size': HIDDEN_SIZE,\n",
    "    'fc_size': FC_SIZE,\n",
    "    'timesteps': TIMESTEPS,\n",
    "    'feature_cols': feature_cols,\n",
    "    'scaler_mean': scaler.mean_,\n",
    "    'scaler_scale': scaler.scale_,\n",
    "    'history': history\n",
    "}, model_path)\n",
    "\n",
    "print(f\"✓ Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf548f7",
   "metadata": {},
   "source": [
    "## 11. Load Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "loaded_model = LSTMModel(\n",
    "    input_size=checkpoint['input_size'],\n",
    "    hidden_size=checkpoint['hidden_size'],\n",
    "    fc_size=checkpoint['fc_size']\n",
    ").to(device)\n",
    "\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded from {model_path}\")\n",
    "print(f\"  Timesteps: {checkpoint['timesteps']}\")\n",
    "print(f\"  Features: {checkpoint['input_size']}\")\n",
    "print(f\"  Best Val AUC: {max(checkpoint['history']['val_auc']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "def predict_sequence(model, scaler, sequence, device):\n",
    "    \"\"\"\n",
    "    Make prediction for a single sequence.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        scaler: Fitted StandardScaler\n",
    "        sequence: Numpy array of shape (timesteps, n_features)\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        probability: Float probability of positive class\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Scale sequence\n",
    "    seq_scaled = scaler.transform(sequence)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    X = torch.FloatTensor(seq_scaled).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        prob = torch.sigmoid(logits).cpu().item()\n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Example: Predict on first test sample\n",
    "sample_idx = 0\n",
    "sample_seq = X_test[sample_idx]\n",
    "true_label = y_test[sample_idx]\n",
    "\n",
    "# Recreate scaler from saved parameters\n",
    "loaded_scaler = StandardScaler()\n",
    "loaded_scaler.mean_ = checkpoint['scaler_mean']\n",
    "loaded_scaler.scale_ = checkpoint['scaler_scale']\n",
    "\n",
    "pred_prob = predict_sequence(loaded_model, loaded_scaler, sample_seq, device)\n",
    "\n",
    "print(f\"Sample prediction:\")\n",
    "print(f\"  True label: {int(true_label)}\")\n",
    "print(f\"  Predicted probability: {pred_prob:.4f}\")\n",
    "print(f\"  Predicted class: {int(pred_prob > 0.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857766cf",
   "metadata": {},
   "source": [
    "## 12. Train Model for Flood Prediction (Optional)\n",
    "\n",
    "Repeat the same process for flood prediction by changing the TARGET variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b32c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train flood model, change TARGET to 'flood_proxy' and re-run cells from section 8 onwards\n",
    "print(\"To train flood prediction model:\")\n",
    "print(\"1. Set TARGET = 'flood_proxy' in section 8\")\n",
    "print(\"2. Re-run cells from section 8 onwards\")\n",
    "print(\"\\nThe model will be saved as models/lstm_flood_proxy.pt\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
